# üß† PLANO DETALHADO - SISTEMA RAG (RETRIEVAL-AUGMENTED GENERATION)

**Data**: 2025-01-27  
**Status**: Planejamento  
**Tecnologia**: PostgreSQL + pgvector

---

## üìã VIS√ÉO GERAL

Sistema RAG que permite agentes de IA:
- **Trabalhar por mais tempo** (contexto persistente)
- **Analisar links e guardar informa√ß√µes** (web scraping + vetoriza√ß√£o)
- **Base de conhecimento** (500 produtos, informa√ß√µes de compra, etc)
- **Sistema de treinamento/feedback loop** (ver perguntas n√£o respondidas e alimentar conhecimento)
- **Melhoria cont√≠nua** (agente fica mais inteligente com o tempo)

---

## üéØ OBJETIVOS PRINCIPAIS

1. **Base de Conhecimento Vetorizada**
   - Armazenar informa√ß√µes de produtos, FAQ, documentos
   - Busca sem√¢ntica usando embeddings
   - Atualiza√ß√£o incremental

2. **An√°lise e Armazenamento de Links**
   - Web scraping de URLs fornecidas
   - Extra√ß√£o de conte√∫do relevante
   - Vetoriza√ß√£o e armazenamento

3. **Sistema de Feedback Loop**
   - Identificar perguntas n√£o respondidas adequadamente
   - Interface para revisar e adicionar respostas corretas
   - Treinamento incremental do agente

4. **Contexto Persistente**
   - Mem√≥ria de longo prazo por agente
   - Hist√≥rico de intera√ß√µes importantes
   - Informa√ß√µes extra√≠das de conversas anteriores

---

## üèóÔ∏è ARQUITETURA PROPOSTA

### 1. Estrutura de Dados (PostgreSQL + pgvector)

#### Tabela: `ai_knowledge_base`
```sql
CREATE TABLE ai_knowledge_base (
    id SERIAL PRIMARY KEY,
    ai_agent_id INT NOT NULL,
    content_type VARCHAR(50) NOT NULL, -- 'product', 'faq', 'document', 'scraped_url', 'conversation_extract'
    title VARCHAR(500),
    content TEXT NOT NULL,
    source_url VARCHAR(1000), -- URL original (se aplic√°vel)
    metadata JSONB, -- Informa√ß√µes adicionais (ex: pre√ßo, categoria, etc)
    embedding vector(1536), -- Embedding OpenAI (1536 dimens√µes para text-embedding-3-small)
    chunk_index INT DEFAULT 0, -- Para documentos grandes divididos em chunks
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    FOREIGN KEY (ai_agent_id) REFERENCES ai_agents(id) ON DELETE CASCADE
);

CREATE INDEX idx_knowledge_agent ON ai_knowledge_base(ai_agent_id);
CREATE INDEX idx_knowledge_type ON ai_knowledge_base(content_type);
CREATE INDEX idx_knowledge_embedding ON ai_knowledge_base USING ivfflat (embedding vector_cosine_ops);
```

#### Tabela: `ai_feedback_loop`
```sql
CREATE TABLE ai_feedback_loop (
    id SERIAL PRIMARY KEY,
    ai_agent_id INT NOT NULL,
    conversation_id INT NOT NULL,
    message_id INT NOT NULL, -- Mensagem do cliente que n√£o foi respondida adequadamente
    user_question TEXT NOT NULL,
    ai_response TEXT, -- Resposta original da IA
    correct_answer TEXT, -- Resposta correta fornecida pelo humano
    status VARCHAR(50) DEFAULT 'pending', -- 'pending', 'reviewed', 'added_to_kb', 'ignored'
    reviewed_by_user_id INT,
    reviewed_at TIMESTAMP,
    added_to_kb BOOLEAN DEFAULT FALSE,
    knowledge_base_id INT, -- ID do registro criado na knowledge base
    created_at TIMESTAMP DEFAULT NOW(),
    FOREIGN KEY (ai_agent_id) REFERENCES ai_agents(id) ON DELETE CASCADE,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE,
    FOREIGN KEY (reviewed_by_user_id) REFERENCES users(id) ON DELETE SET NULL,
    FOREIGN KEY (knowledge_base_id) REFERENCES ai_knowledge_base(id) ON DELETE SET NULL
);

CREATE INDEX idx_feedback_agent ON ai_feedback_loop(ai_agent_id);
CREATE INDEX idx_feedback_status ON ai_feedback_loop(status);
CREATE INDEX idx_feedback_pending ON ai_feedback_loop(ai_agent_id, status) WHERE status = 'pending';
```

#### Tabela: `ai_url_scraping`
```sql
CREATE TABLE ai_url_scraping (
    id SERIAL PRIMARY KEY,
    ai_agent_id INT NOT NULL,
    url VARCHAR(1000) NOT NULL,
    title VARCHAR(500),
    content TEXT,
    scraped_at TIMESTAMP DEFAULT NOW(),
    status VARCHAR(50) DEFAULT 'pending', -- 'pending', 'processing', 'completed', 'failed'
    error_message TEXT,
    chunks_created INT DEFAULT 0,
    FOREIGN KEY (ai_agent_id) REFERENCES ai_agents(id) ON DELETE CASCADE
);

CREATE INDEX idx_scraping_agent ON ai_url_scraping(ai_agent_id);
CREATE INDEX idx_scraping_status ON ai_url_scraping(status);
CREATE UNIQUE INDEX idx_scraping_url_agent ON ai_url_scraping(ai_agent_id, url);
```

#### Tabela: `ai_agent_memory`
```sql
CREATE TABLE ai_agent_memory (
    id SERIAL PRIMARY KEY,
    ai_agent_id INT NOT NULL,
    conversation_id INT NOT NULL,
    memory_type VARCHAR(50) NOT NULL, -- 'fact', 'preference', 'context', 'extracted_info'
    key VARCHAR(255), -- Chave identificadora (ex: 'contact_email', 'product_interest')
    value TEXT NOT NULL,
    importance DECIMAL(3,2) DEFAULT 0.5, -- 0.0 a 1.0
    expires_at TIMESTAMP, -- NULL = permanente
    created_at TIMESTAMP DEFAULT NOW(),
    FOREIGN KEY (ai_agent_id) REFERENCES ai_agents(id) ON DELETE CASCADE,
    FOREIGN KEY (conversation_id) REFERENCES conversations(id) ON DELETE CASCADE
);

CREATE INDEX idx_memory_agent ON ai_agent_memory(ai_agent_id);
CREATE INDEX idx_memory_conversation ON ai_agent_memory(conversation_id);
CREATE INDEX idx_memory_key ON ai_agent_memory(ai_agent_id, key);
```

---

## üîÑ FLUXO DE FUNCIONAMENTO

### 1. Processamento de Mensagem com RAG

```
1. Cliente envia mensagem
   ‚Üì
2. Sistema busca contexto relevante na knowledge base:
   a) Gera embedding da mensagem do cliente
   b) Busca similaridade no pgvector (cosine similarity)
   c) Retorna top 5-10 chunks mais relevantes
   ‚Üì
3. Monta prompt com:
   - Prompt do agente
   - Contexto relevante da knowledge base
   - Mem√≥ria persistente do agente
   - Hist√≥rico da conversa
   - Tools dispon√≠veis
   ‚Üì
4. Chama OpenAI API
   ‚Üì
5. Se resposta n√£o √© confi√°vel ou cliente pede esclarecimento:
   a) Registra em feedback_loop (status: pending)
   b) Escala para humano se necess√°rio
   ‚Üì
6. Se resposta √© boa:
   a) Extrai informa√ß√µes importantes para mem√≥ria
   b) Salva em ai_agent_memory
   ‚Üì
7. Envia resposta ao cliente
```

### 2. Sistema de Feedback Loop

```
1. Agente responde pergunta do cliente
   ‚Üì
2. Sistema detecta sinais de resposta inadequada:
   - Cliente pede esclarecimento
   - Cliente diz "n√£o entendi"
   - Cliente escala para humano
   - Resposta tem baixa confian√ßa (score < 0.7)
   ‚Üì
3. Registra em ai_feedback_loop (status: pending)
   ‚Üì
4. Admin/Agente revisa:
   - V√™ pergunta original
   - V√™ resposta da IA
   - Fornece resposta correta
   ‚Üì
5. Sistema adiciona √† knowledge base:
   a) Cria embedding da resposta correta
   b) Salva em ai_knowledge_base
   c) Atualiza feedback_loop (status: added_to_kb)
   ‚Üì
6. Pr√≥xima vez que pergunta similar aparecer:
   - Sistema encontra resposta correta na KB
   - Agente responde corretamente
```

### 3. An√°lise e Armazenamento de Links

```
1. Admin fornece URL para o agente
   OU
   Cliente envia link durante conversa
   ‚Üì
2. Sistema registra em ai_url_scraping (status: pending)
   ‚Üì
3. Job em background processa:
   a) Faz web scraping da URL
   b) Extrai conte√∫do relevante (texto, t√≠tulos, etc)
   c) Remove HTML, limpa texto
   d) Divide em chunks (m√°x 1000 tokens cada)
   ‚Üì
4. Para cada chunk:
   a) Gera embedding usando OpenAI
   b) Salva em ai_knowledge_base
   c) Associa ao ai_url_scraping
   ‚Üì
5. Atualiza ai_url_scraping (status: completed, chunks_created: X)
```

---

## üõ†Ô∏è COMPONENTES A IMPLEMENTAR

### 1. Services

#### `RAGService.php`
```php
class RAGService
{
    // Buscar contexto relevante da knowledge base
    public static function searchRelevantContext(int $agentId, string $query, int $limit = 5): array
    
    // Adicionar conhecimento √† base
    public static function addKnowledge(int $agentId, string $content, string $contentType, array $metadata = []): int
    
    // Gerar embedding usando OpenAI
    public static function generateEmbedding(string $text): array
    
    // Buscar similaridade no pgvector
    public static function findSimilar(int $agentId, array $queryEmbedding, int $limit = 5): array
}
```

#### `URLScrapingService.php`
```php
class URLScrapingService
{
    // Adicionar URL para scraping
    public static function addUrl(int $agentId, string $url): int
    
    // Processar URL (web scraping)
    public static function processUrl(int $scrapingId): bool
    
    // Dividir conte√∫do em chunks
    public static function chunkContent(string $content, int $maxTokens = 1000): array
}
```

#### `FeedbackLoopService.php`
```php
class FeedbackLoopService
{
    // Registrar feedback negativo
    public static function registerFeedback(int $agentId, int $conversationId, int $messageId, string $question, string $aiResponse): int
    
    // Revisar feedback e adicionar resposta correta
    public static function reviewFeedback(int $feedbackId, int $userId, string $correctAnswer, bool $addToKB = true): bool
    
    // Obter feedbacks pendentes
    public static function getPendingFeedbacks(int $agentId, int $limit = 50): array
}
```

#### `AgentMemoryService.php`
```php
class AgentMemoryService
{
    // Salvar mem√≥ria
    public static function saveMemory(int $agentId, int $conversationId, string $type, string $key, string $value, float $importance = 0.5): int
    
    // Buscar mem√≥rias relevantes
    public static function getRelevantMemories(int $agentId, int $conversationId): array
    
    // Extrair informa√ß√µes importantes da conversa
    public static function extractImportantInfo(int $agentId, int $conversationId, array $messages): array
}
```

### 2. Models

- `AIKnowledgeBase.php` - Model para knowledge base
- `AIFeedbackLoop.php` - Model para feedback loop
- `AIUrlScraping.php` - Model para URLs sendo processadas
- `AIAgentMemory.php` - Model para mem√≥ria persistente

### 3. Controllers

- `RAGController.php` - Gerenciar knowledge base
- `FeedbackLoopController.php` - Interface de revis√£o de feedbacks
- `URLScrapingController.php` - Adicionar/processar URLs

### 4. Migrations

- `060_create_ai_knowledge_base_table.php`
- `061_create_ai_feedback_loop_table.php`
- `062_create_ai_url_scraping_table.php`
- `063_create_ai_agent_memory_table.php`
- `064_add_pgvector_extension.php` - Instalar extens√£o pgvector

### 5. Jobs (Background Processing)

- `ProcessURLScrapingJob.php` - Processar URLs em background
- `GenerateEmbeddingsJob.php` - Gerar embeddings em background
- `ExtractConversationInfoJob.php` - Extrair informa√ß√µes importantes de conversas

---

## üîå INTEGRA√á√ÉO COM OPENAI

### Embeddings

**Model Recomendado**: `text-embedding-3-small` (1536 dimens√µes)
- Mais barato: $0.02 por 1M tokens
- Boa qualidade para busca sem√¢ntica
- R√°pido

**Alternativa**: `text-embedding-3-large` (3072 dimens√µes)
- Melhor qualidade
- Mais caro: $0.13 por 1M tokens
- Mais lento

### Processo de Gera√ß√£o de Embedding

```php
// 1. Preparar texto (limpar, normalizar)
$cleanText = self::cleanText($text);

// 2. Chamar OpenAI Embeddings API
$response = self::callOpenAIEmbeddingsAPI($cleanText);

// 3. Obter vetor (1536 dimens√µes)
$embedding = $response['data'][0]['embedding'];

// 4. Salvar no PostgreSQL com pgvector
// INSERT INTO ai_knowledge_base (embedding) VALUES ($1::vector)
```

---

## üìä BUSCA SEM√ÇNTICA COM pgvector

### Exemplo de Query

```sql
-- Buscar chunks mais similares
SELECT 
    id,
    title,
    content,
    content_type,
    1 - (embedding <=> $1::vector) as similarity
FROM ai_knowledge_base
WHERE ai_agent_id = $2
ORDER BY embedding <=> $1::vector
LIMIT 5;
```

**Operadores pgvector**:
- `<=>` - Cosine distance (recomendado para embeddings)
- `<->` - Euclidean distance
- `<#>` - Negative inner product

### Otimiza√ß√£o com √çndices

```sql
-- Criar √≠ndice IVFFlat (mais r√°pido para busca)
CREATE INDEX idx_knowledge_embedding ON ai_knowledge_base 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- Para bases muito grandes (> 1M registros), usar HNSW
CREATE INDEX idx_knowledge_embedding_hnsw ON ai_knowledge_base 
USING hnsw (embedding vector_cosine_ops);
```

---

## üé® INTERFACE DE USU√ÅRIO

### 1. P√°gina de Knowledge Base (`/ai-agents/{id}/knowledge-base`)

**Funcionalidades**:
- Listar todos os conhecimentos do agente
- Buscar por texto (busca sem√¢ntica)
- Adicionar conhecimento manualmente
- Importar de URL
- Importar produtos (CSV/JSON)
- Editar/Excluir conhecimentos
- Visualizar similaridade entre conhecimentos

**Componentes**:
- Tabela de conhecimentos com filtros
- Modal para adicionar conhecimento
- Modal para importar URL
- Modal para importar produtos em massa
- Visualiza√ß√£o de chunks (se documento grande)

### 2. P√°gina de Feedback Loop (`/ai-agents/{id}/feedback`)

**Funcionalidades**:
- Listar feedbacks pendentes
- Ver pergunta original + resposta da IA
- Fornecer resposta correta
- Adicionar √† knowledge base automaticamente
- Ignorar feedback (marcar como ignorado)
- Hist√≥rico de feedbacks revisados

**Componentes**:
- Lista de feedbacks pendentes (prioridade alta)
- Card de revis√£o com:
  - Pergunta do cliente
  - Resposta da IA (com score de confian√ßa)
  - Campo para resposta correta
  - Checkbox "Adicionar √† knowledge base"
  - Bot√£o "Salvar e Adicionar"
  - Bot√£o "Ignorar"

### 3. P√°gina de URLs (`/ai-agents/{id}/urls`)

**Funcionalidades**:
- Listar URLs sendo processadas
- Adicionar nova URL
- Ver status de processamento
- Ver chunks criados
- Reprocessar URL (se falhou)

**Componentes**:
- Tabela de URLs com status
- Modal para adicionar URL
- Progress bar para URLs em processamento
- Visualiza√ß√£o de conte√∫do extra√≠do

### 4. P√°gina de Mem√≥ria (`/ai-agents/{id}/memory`)

**Funcionalidades**:
- Ver mem√≥rias do agente
- Filtrar por tipo (fact, preference, context)
- Ver mem√≥rias por conversa
- Editar/Excluir mem√≥rias
- Ver import√¢ncia de cada mem√≥ria

**Componentes**:
- Lista de mem√≥rias com filtros
- Cards de mem√≥ria com:
  - Tipo e import√¢ncia
  - Chave e valor
  - Conversa associada
  - Data de cria√ß√£o

---

## üîÑ FLUXO DE TREINAMENTO INCREMENTAL

### Processo Completo

```
1. Agente responde pergunta
   ‚Üì
2. Sistema avalia qualidade:
   - Score de confian√ßa da resposta
   - Feedback do cliente (expl√≠cito ou impl√≠cito)
   - Escala√ß√£o para humano
   ‚Üì
3. Se qualidade baixa:
   a) Registra em feedback_loop
   b) Notifica admin/agente para revisar
   ‚Üì
4. Admin revisa e fornece resposta correta
   ‚Üì
5. Sistema adiciona √† knowledge base:
   a) Gera embedding da resposta correta
   b) Salva com metadata (tipo, tags, etc)
   ‚Üì
6. Pr√≥xima pergunta similar:
   a) Busca na KB encontra resposta correta
   b) Agente responde melhor
   ‚Üì
7. Loop continua ‚Üí Agente melhora continuamente
```

### M√©tricas de Melhoria

- **Taxa de Respostas Corretas**: % de respostas que n√£o precisaram de revis√£o
- **Taxa de Escala√ß√£o**: % de conversas escaladas para humano
- **Score M√©dio de Confian√ßa**: Confian√ßa m√©dia das respostas
- **Feedbacks Pendentes**: Quantidade de feedbacks aguardando revis√£o
- **Conhecimentos Adicionados**: Total de conhecimentos na base

---

## üöÄ IMPLEMENTA√á√ÉO POR FASES

### Fase 1: Infraestrutura Base (Semana 1-2)

**Objetivo**: Configurar PostgreSQL + pgvector e estrutura b√°sica

**Tarefas**:
1. ‚úÖ Instalar PostgreSQL no VPS
2. ‚úÖ Instalar extens√£o pgvector
3. ‚úÖ Criar migrations das tabelas
4. ‚úÖ Criar Models b√°sicos
5. ‚úÖ Configurar conex√£o PostgreSQL no sistema

**Entreg√°veis**:
- PostgreSQL rodando com pgvector
- Tabelas criadas
- Models funcionando

### Fase 2: Servi√ßos Core (Semana 2-3)

**Objetivo**: Implementar servi√ßos de RAG b√°sicos

**Tarefas**:
1. ‚úÖ Criar `RAGService` com busca sem√¢ntica
2. ‚úÖ Criar `EmbeddingService` (integra√ß√£o OpenAI)
3. ‚úÖ Integrar busca RAG no `OpenAIService`
4. ‚úÖ Testar busca sem√¢ntica

**Entreg√°veis**:
- Busca sem√¢ntica funcionando
- Integra√ß√£o com OpenAI Embeddings API
- Agente usando contexto da KB

### Fase 3: Sistema de Feedback (Semana 3-4)

**Objetivo**: Implementar feedback loop completo

**Tarefas**:
1. ‚úÖ Criar `FeedbackLoopService`
2. ‚úÖ Detectar respostas inadequadas automaticamente
3. ‚úÖ Interface de revis√£o de feedbacks
4. ‚úÖ Adicionar √† KB ap√≥s revis√£o

**Entreg√°veis**:
- Sistema de feedback funcionando
- Interface de revis√£o
- Adi√ß√£o autom√°tica √† KB

### Fase 4: Web Scraping (Semana 4-5)

**Objetivo**: Implementar an√°lise e armazenamento de URLs

**Tarefas**:
1. ‚úÖ Criar `URLScrapingService`
2. ‚úÖ Implementar web scraping (usar biblioteca como Goutte ou Guzzle + DOM)
3. ‚úÖ Dividir conte√∫do em chunks
4. ‚úÖ Gerar embeddings e salvar
5. ‚úÖ Job em background para processar URLs

**Entreg√°veis**:
- Web scraping funcionando
- URLs sendo processadas automaticamente
- Conte√∫do sendo adicionado √† KB

### Fase 5: Sistema de Mem√≥ria (Semana 5-6)

**Objetivo**: Implementar mem√≥ria persistente

**Tarefas**:
1. ‚úÖ Criar `AgentMemoryService`
2. ‚úÖ Extrair informa√ß√µes importantes de conversas
3. ‚úÖ Salvar mem√≥rias automaticamente
4. ‚úÖ Usar mem√≥rias no contexto do agente

**Entreg√°veis**:
- Mem√≥ria persistente funcionando
- Informa√ß√µes sendo extra√≠das automaticamente
- Contexto melhorado com mem√≥rias

### Fase 6: Interface Completa (Semana 6-7)

**Objetivo**: Criar todas as interfaces de usu√°rio

**Tarefas**:
1. ‚úÖ P√°gina de Knowledge Base
2. ‚úÖ P√°gina de Feedback Loop
3. ‚úÖ P√°gina de URLs
4. ‚úÖ P√°gina de Mem√≥ria
5. ‚úÖ Melhorias de UX

**Entreg√°veis**:
- Todas as interfaces funcionando
- Sistema completo e testado

---

## üí° MELHORIAS E SUGEST√ïES

### 1. Chunking Inteligente

**Problema**: Dividir documentos grandes em chunks pode quebrar contexto

**Solu√ß√£o**: 
- Usar chunking sem√¢ntico (dividir por par√°grafos/t√≥picos)
- Overlap entre chunks (√∫ltimos 100 tokens do chunk anterior)
- Manter metadata de chunk anterior/pr√≥ximo

### 2. Re-ranking de Resultados

**Problema**: Busca por similaridade pode retornar resultados n√£o relevantes

**Solu√ß√£o**:
- Usar modelo de re-ranking (ex: Cohere Rerank API)
- Combinar similaridade vetorial + BM25 (busca textual)
- Score h√≠brido: `final_score = 0.7 * vector_score + 0.3 * text_score`

### 3. Cache de Embeddings

**Problema**: Gerar embeddings √© caro e lento

**Solu√ß√£o**:
- Cachear embeddings de textos comuns
- Usar hash do texto como chave
- Cache em Redis ou PostgreSQL

### 4. Limpeza Autom√°tica

**Problema**: Knowledge base pode ficar desatualizada

**Solu√ß√£o**:
- Sistema de versionamento (manter hist√≥rico)
- Marcar conhecimentos como "obsoletos"
- Limpeza autom√°tica de conhecimentos n√£o usados h√° X tempo
- Re-embedding peri√≥dico de conhecimentos importantes

### 5. Multi-Agent Knowledge Sharing

**Problema**: Cada agente tem sua pr√≥pria KB (pode duplicar conhecimento)

**Solu√ß√£o**:
- KB global compartilhada
- KB por agente (espec√≠fica)
- Sistema de heran√ßa (agente herda da KB global + espec√≠fica)

### 6. An√°lise de Qualidade de Respostas

**Problema**: Como saber se resposta foi boa?

**Solu√ß√£o**:
- Score de confian√ßa da IA (j√° existe)
- An√°lise de sentimento da resposta do cliente
- Detec√ß√£o de palavras-chave ("n√£o entendi", "obrigado", etc)
- Tempo at√© pr√≥xima mensagem (se cliente n√£o responde r√°pido, pode ter ficado satisfeito)

### 7. A/B Testing de Conhecimentos

**Problema**: Como saber qual conhecimento √© melhor?

**Solu√ß√£o**:
- Testar m√∫ltiplas vers√µes de conhecimento
- Medir taxa de sucesso de cada vers√£o
- Escolher automaticamente melhor vers√£o

### 8. Importa√ß√£o em Massa

**Funcionalidades**:
- Importar produtos via CSV/JSON
- Importar FAQ via CSV
- Importar documentos (PDF, DOCX)
- API para adicionar conhecimentos programaticamente

### 9. Sistema de Tags e Categorias

**Funcionalidades**:
- Tagar conhecimentos (ex: "produto", "pre√ßo", "entrega")
- Filtrar busca por tags
- Categorias hier√°rquicas

### 10. An√°lise de Gaps de Conhecimento

**Funcionalidades**:
- Identificar perguntas frequentes sem resposta na KB
- Sugerir conhecimentos a adicionar
- Dashboard de gaps de conhecimento

---

## üìà M√âTRICAS E ANALYTICS

### M√©tricas da Knowledge Base

- Total de conhecimentos
- Conhecimentos por tipo
- Taxa de uso (quantas vezes cada conhecimento foi usado)
- Conhecimentos mais √∫teis (top 10)
- Conhecimentos nunca usados (candidatos a remo√ß√£o)

### M√©tricas de Feedback Loop

- Total de feedbacks pendentes
- Taxa de feedbacks revisados
- Tempo m√©dio de revis√£o
- Taxa de adi√ß√£o √† KB ap√≥s revis√£o
- Melhoria ao longo do tempo (gr√°fico)

### M√©tricas de URLs

- Total de URLs processadas
- Taxa de sucesso de scraping
- Chunks criados por URL
- URLs mais √∫teis (baseado em uso)

### M√©tricas de Mem√≥ria

- Total de mem√≥rias
- Mem√≥rias por tipo
- Mem√≥rias mais importantes
- Mem√≥rias expiradas (limpeza)

---

## üîí SEGURAN√áA E VALIDA√á√ÉO

### Valida√ß√µes Necess√°rias

1. **URLs**:
   - Validar formato de URL
   - Verificar se URL √© acess√≠vel
   - Rate limiting de scraping (n√£o sobrecarregar servidor)
   - Whitelist/Blacklist de dom√≠nios

2. **Conte√∫do**:
   - Sanitizar HTML de URLs
   - Validar tamanho m√°ximo de conte√∫do
   - Prevenir injection de c√≥digo malicioso

3. **Embeddings**:
   - Validar dimens√µes do embedding (deve ser 1536)
   - Rate limiting de gera√ß√£o de embeddings
   - Cache para evitar duplicatas

4. **Acesso**:
   - Verificar permiss√µes antes de adicionar conhecimento
   - Logs de todas as a√ß√µes
   - Auditoria de mudan√ßas na KB

---

## üí∞ ESTIMATIVA DE CUSTOS

### OpenAI Embeddings API

**Model**: `text-embedding-3-small`
- **Pre√ßo**: $0.02 por 1M tokens
- **Exemplo**: 500 produtos √ó 500 tokens cada = 250K tokens = $0.005

**Custo Mensal Estimado**:
- 10.000 conhecimentos √ó 500 tokens = 5M tokens = **$0.10/m√™s**
- 100 URLs/dia √ó 2000 tokens = 200K tokens/dia = 6M tokens/m√™s = **$0.12/m√™s**
- **Total**: ~$0.25/m√™s (muito barato!)

### PostgreSQL + pgvector

- **Custo**: $0 (self-hosted)
- **Requisitos**: VPS com PostgreSQL 12+ e pgvector instalado

---

## üéØ PR√ìXIMOS PASSOS RECOMENDADOS

### Ordem de Implementa√ß√£o Sugerida

1. **Semana 1**: Configurar PostgreSQL + pgvector no VPS
2. **Semana 2**: Criar migrations e models b√°sicos
3. **Semana 3**: Implementar `RAGService` e busca sem√¢ntica b√°sica
4. **Semana 4**: Integrar RAG no `OpenAIService` (usar contexto da KB)
5. **Semana 5**: Implementar sistema de feedback loop b√°sico
6. **Semana 6**: Criar interface de revis√£o de feedbacks
7. **Semana 7**: Implementar web scraping b√°sico
8. **Semana 8**: Criar interfaces completas
9. **Semana 9**: Implementar sistema de mem√≥ria
10. **Semana 10**: Testes, ajustes e melhorias

---

## üìö BIBLIOTECAS E DEPEND√äNCIAS

### PHP

```json
{
    "require": {
        "symfony/dom-crawler": "^6.0", // Web scraping
        "guzzlehttp/guzzle": "^7.0", // HTTP client
        "doctrine/dbal": "^3.0" // Para trabalhar com PostgreSQL
    }
}
```

### PostgreSQL

- **PostgreSQL**: 12+ (recomendado 14+)
- **pgvector**: Extens√£o para vetoriza√ß√£o
- **Instala√ß√£o**: `CREATE EXTENSION vector;`

### Node.js (Opcional - para processamento pesado)

- **Puppeteer**: Para scraping de SPAs (React, Vue, etc)
- **Cheerio**: Para parsing HTML r√°pido

---

## üß™ TESTES SUGERIDOS

### Testes Unit√°rios

- Gera√ß√£o de embeddings
- Busca sem√¢ntica
- Chunking de conte√∫do
- Extra√ß√£o de informa√ß√µes

### Testes de Integra√ß√£o

- Fluxo completo de RAG
- Feedback loop completo
- Web scraping completo
- Sistema de mem√≥ria completo

### Testes de Performance

- Busca sem√¢ntica com 10K+ conhecimentos
- Gera√ß√£o de embeddings em batch
- Web scraping de m√∫ltiplas URLs simult√¢neas

---

## üìù NOTAS IMPORTANTES

### Considera√ß√µes T√©cnicas

1. **pgvector vs Milvus/Pinecone**:
   - **pgvector**: Self-hosted, integrado ao PostgreSQL, gratuito
   - **Milvus**: Mais perform√°tico, mas requer servidor separado
   - **Pinecone**: SaaS, mais f√°cil, mas pago
   - **Recomenda√ß√£o**: Come√ßar com pgvector (j√° tem PostgreSQL)

2. **Dimens√µes do Embedding**:
   - OpenAI `text-embedding-3-small`: 1536 dimens√µes
   - OpenAI `text-embedding-3-large`: 3072 dimens√µes
   - **Recomenda√ß√£o**: Come√ßar com `small` (mais barato, suficiente)

3. **Tamanho de Chunks**:
   - M√°ximo recomendado: 1000 tokens
   - Overlap recomendado: 100-200 tokens
   - **Recomenda√ß√£o**: 800 tokens por chunk, 150 tokens de overlap

4. **√çndices pgvector**:
   - **IVFFlat**: Mais r√°pido para criar, bom para < 1M registros
   - **HNSW**: Mais r√°pido para buscar, melhor para > 1M registros
   - **Recomenda√ß√£o**: Come√ßar com IVFFlat, migrar para HNSW se necess√°rio

---

## ‚úÖ CHECKLIST DE IMPLEMENTA√á√ÉO

### Infraestrutura
- [ ] PostgreSQL instalado no VPS
- [ ] Extens√£o pgvector instalada
- [ ] Conex√£o PostgreSQL configurada no sistema
- [ ] Migrations criadas e executadas

### Backend
- [ ] Models criados (AIKnowledgeBase, AIFeedbackLoop, etc)
- [ ] RAGService implementado
- [ ] EmbeddingService implementado
- [ ] FeedbackLoopService implementado
- [ ] URLScrapingService implementado
- [ ] AgentMemoryService implementado
- [ ] Integra√ß√£o com OpenAIService

### Frontend
- [ ] P√°gina de Knowledge Base
- [ ] P√°gina de Feedback Loop
- [ ] P√°gina de URLs
- [ ] P√°gina de Mem√≥ria
- [ ] Modais de adi√ß√£o/edi√ß√£o

### Jobs
- [ ] Job de processamento de URLs
- [ ] Job de gera√ß√£o de embeddings
- [ ] Job de extra√ß√£o de informa√ß√µes

### Testes
- [ ] Testes unit√°rios
- [ ] Testes de integra√ß√£o
- [ ] Testes de performance

---

**√öltima atualiza√ß√£o**: 2025-01-27  
**Vers√£o do Plano**: 1.0

